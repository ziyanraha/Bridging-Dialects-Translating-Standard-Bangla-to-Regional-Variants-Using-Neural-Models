{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xccHTUA4drLj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzSkC1vPe4Z6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PpZs5YwftMW"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Train/Mymensingh Train Translation.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Test/Mymensingh Test Translation.csv\")\n",
        "validation_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Validation/Mymensingh Validation Translation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OejQOMqbgXBo"
      },
      "outputs": [],
      "source": [
        "train_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL690gKN1fo5"
      },
      "outputs": [],
      "source": [
        "train_data.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sBumGdygZoQ"
      },
      "outputs": [],
      "source": [
        "test_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpvaSQMc1kJi"
      },
      "outputs": [],
      "source": [
        "test_data.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjJX-qYBgbOB"
      },
      "outputs": [],
      "source": [
        "validation_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0-WYx7S1ptc"
      },
      "outputs": [],
      "source": [
        "validation_data.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJjxfCbROQF2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjAFH_OYaGBd"
      },
      "outputs": [],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbXwlOOKaNPw"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6vnIX2PcGE5"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esPlJFmQe5lk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWIUgjZqcobw"
      },
      "outputs": [],
      "source": [
        "!transformers-cli cache clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idYkCKoYLAkK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehyMslAiLEdi"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3y3J7pKLHo8"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o16Pwu4BRJED"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQyLIu29LM05"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers==4.10.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWyS4kEnRi-v"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTWQoot8LNs2"
      },
      "outputs": [],
      "source": [
        "#!pip install accelerate==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY1P_thOZs0z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "from normalizer import normalize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sacrebleu import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r2KXdcLOII8"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Train/Mymensingh Train Translation.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Test/Mymensingh Test Translation.csv\")\n",
        "validation_data = pd.read_csv(\"/content/drive/MyDrive/Vashantor_CSV_Format/Validation/Mymensingh Validation Translation.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N7XBlRTfUUI"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw5GFgwM8adU"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop(columns=['banglish_speech ','mymensingh_banglish_speech ','region_name ','english_speech'],axis=1)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyEST6yhfd89"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.drop(columns=['banglish_speech ','mymensingh_banglish_speech ','region_name ','english_speech'],axis=1)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol-1vjf7ofXK"
      },
      "outputs": [],
      "source": [
        "train_data.rename(columns={'bangla_speech ': 'input_text', 'mymensingh_bangla_speech '\t: 'labels'}, inplace=True)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx3Dgo0WgLSu"
      },
      "outputs": [],
      "source": [
        "# Rename the columns to match the expected format\n",
        "test_data.rename(columns={'bangla_speech ': 'input_text', 'mymensingh_bangla_speech '\t: 'labels'}, inplace=True)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niWA4tjcfeDt"
      },
      "outputs": [],
      "source": [
        "validation_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP4PqEkip568"
      },
      "outputs": [],
      "source": [
        "validation_data = validation_data.drop(columns=['banglish_speech ','mymensingh_banglish_speech ','region_name ','english_speech'],axis=1)\n",
        "validation_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5md8H5UqgUkv"
      },
      "outputs": [],
      "source": [
        "# Rename the columns to match the expected format\n",
        "validation_data.rename(columns={'bangla_speech ': 'input_text', 'mymensingh_bangla_speech '\t: 'labels'}, inplace=True)\n",
        "validation_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4XLDQuiy_p2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXMdljv9IEv1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from normalizer import normalize\n",
        "from transformers import MT5ForConditionalGeneration, AutoTokenizer ,DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsIxClpzOVGu"
      },
      "outputs": [],
      "source": [
        "model_name = \"csebuetnlp/banglat5\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_N5Dzib18PO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKGRnuEh0TGb"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: A DataFrame containing 'input_text' and 'labels' columns.\n",
        "            tokenizer: A Hugging Face tokenizer.\n",
        "            max_length: Maximum sequence length.\n",
        "        \"\"\"\n",
        "        self.input_text = data['input_text'].apply(normalize).tolist()\n",
        "        self.labels = data['labels'].apply(normalize).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text = self.input_text[idx]\n",
        "        label_text = self.labels[idx]\n",
        "\n",
        "        # Tokenize the input text\n",
        "        input_encodings = self.tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize the label text to get its 'input_ids' and 'attention_mask'\n",
        "        label_encodings = self.tokenizer(\n",
        "            label_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encodings['input_ids'].squeeze(),\n",
        "            'attention_mask': input_encodings['attention_mask'].squeeze(),\n",
        "            'labels': label_encodings['input_ids'].squeeze(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LStEDAlZ1wYg"
      },
      "outputs": [],
      "source": [
        "# Create train , test and validation datasets\n",
        "train_dataset = Seq2SeqDataset(train_data, tokenizer)\n",
        "test_dataset = Seq2SeqDataset(test_data, tokenizer)\n",
        "validation_dataset = Seq2SeqDataset(validation_data, tokenizer)\n",
        "\n",
        "# Create train , test and validation dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)  #batch_size=32\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16) #batch_size=32\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=16) #batch_size=32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd87PmBkeAY2"
      },
      "outputs": [],
      "source": [
        "# Move the model to the device (CPU or GPU)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8zEQdUrtwF2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeLUY2rez8s1"
      },
      "outputs": [],
      "source": [
        "#pip install transformers==4.30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lieCrycOdqHr"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "from transformers import AdamW\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Create a custom optimizer using torch.optim.AdamW\n",
        "custom_optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,  # Learning rate\n",
        "    eps=1e-8,  # Epsilon value to prevent division by zero\n",
        "    weight_decay=0.01,  # Weight decay (L2 regularization)\n",
        ")\n",
        "\n",
        "#if you have 1,000 training examples and a batch size of 100, you would have 10 iterations in each epoch (1,000 / 100 = 10)\n",
        "'''\n",
        "This parameter determines how many small batches are accumulated before performing a weight update.\n",
        "In your code, it's set to 8, which means you'll accumulate gradients over 8 small batches before performing a weight update.\n",
        "This effectively simulates a larger batch size without requiring more GPU memory.\n",
        "So, you are updating the model's weights less frequently compared to the number of actual batches processed.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Learning rate determines how quickly the model learns from the data.\n",
        "The learning rate scheduler type is set to \"cosine_with_restarts,\" which is a type of learning rate schedule.\n",
        " Warmup steps are the number of initial training steps with a smaller learning rate, and weight decay introduces L2 regularization to the optimizer.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Number of Iterations per Epoch = Number of Training Samples / Batch Size\n",
        "Total Iterations = Number of Iterations per Epoch * Number of Epochs\n",
        "'''\n",
        "# Define the TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/Movies',\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",  # Align save strategy with evaluation strategy\n",
        "    ##save_total_limit=1,\n",
        "    #save_steps=700,\n",
        "    learning_rate=1e-3,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    #load_best_model_at_end=True,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/Movies',\n",
        "    logging_steps=10,  # Log every 10 steps,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM7jobxRCQ3C"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Create a data collator for sequence-to-sequence tasks\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,  # Your Hugging Face tokenizer\n",
        "    model=model,\n",
        "    padding=True,\n",
        "    max_length=128,\n",
        "    label_pad_token_id=tokenizer.pad_token_id,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc0oxhBLCRP6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the Trainer with the custom optimizer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    optimizers=(custom_optimizer, None),  # Pass the custom optimizer here\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRbFX1xIvIuD"
      },
      "source": [
        "# **Training start here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXhfpwIuYqdH"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izuKgQ4UUgLN"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYgonbylUuHx"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL4RCOHgU9tA"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ySxLtGWb8eM"
      },
      "outputs": [],
      "source": [
        "# Move the model to the device (CPU or GPU)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0oB40J3jc_B"
      },
      "outputs": [],
      "source": [
        "!pip install rouge-score\n",
        "#https://github.com/google-research/google-research/tree/master/rouge\n",
        "#https://huggingface.co/spaces/evaluate-metric/rouge [Different types of ROUGE scores]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGt3awYZlEyC"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CckuFHvsvy"
      },
      "source": [
        "# **Loading evaluation metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFL6okK2jKb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import Levenshtein\n",
        "from evaluate import load\n",
        "# Define the move_to_device function\n",
        "def move_to_device(batch, device):\n",
        "    if isinstance(batch, torch.Tensor):\n",
        "        return batch.to(device)\n",
        "    elif isinstance(batch, list):\n",
        "        return [move_to_device(item, device) for item in batch]\n",
        "    elif isinstance(batch, dict):\n",
        "        return {key: move_to_device(value, device) for key, value in batch.items()}\n",
        "    else:\n",
        "        return batch  # If it's not a tensor, list, or dict, leave it as is\n",
        "\n",
        "# Load the evaluation metric for Character Error Rate (CER) and Word Error Rate (WER) and Exact Match(em)\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "meteor = load('meteor')\n",
        "exact_match_metric = load(\"exact_match\")\n",
        "\n",
        "# Load BLEU and ROUGE metrics\n",
        "bleu_metric = load(\"bleu\")\n",
        "rouge_metric = load('rouge')\n",
        "\n",
        "# Initialize lists to store generated translations and references\n",
        "generated_translations = []\n",
        "references = []\n",
        "\n",
        "# Generate translations for the test dataset\n",
        "for batch in test_dataloader:\n",
        "    # Move the batch to CUDA\n",
        "    batch = move_to_device(batch, 'cuda')\n",
        "\n",
        "    input_text = batch['input_ids']  # Access the input_text using the correct key\n",
        "    labels = batch['labels']  # Access the labels using the correct key\n",
        "\n",
        "    # Generate translations\n",
        "    translation_ids = model.generate(input_text, max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "    # Move the translation_ids to CPU to decode\n",
        "    translation_ids = translation_ids.to('cpu')\n",
        "\n",
        "    generated_translation = tokenizer.batch_decode(translation_ids, skip_special_tokens=True)\n",
        "\n",
        "    generated_translations.extend(generated_translation)\n",
        "    references.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))  # Decoding the label IDs\n",
        "\n",
        "# Make sure to move generated_translations back to CPU for evaluation if necessary\n",
        "generated_translations = [translation if not isinstance(translation, str) else translation for translation in generated_translations]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX5HA_74qZsI"
      },
      "outputs": [],
      "source": [
        "# Calculate Character Error Rate (CER) and Word Error Rate (WER)\n",
        "results_CER = cer_metric.compute(predictions=generated_translations, references=references)\n",
        "results_WER = wer_metric.compute(predictions=generated_translations, references=references)\n",
        "\n",
        "# Calculate Exact Match (EM) and METEOR(M)\n",
        "results_em = exact_match_metric.compute(predictions=generated_translations, references=references)\n",
        "results_met = meteor.compute(predictions=generated_translations, references=references)\n",
        "\n",
        "# Calculate Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE)\n",
        "results_bleu = bleu_metric.compute(predictions=generated_translations, references=references)\n",
        "results_rouge = rouge_metric.compute(predictions=generated_translations, references=references)\n",
        "\n",
        "\n",
        "# Calculate Levenshtein Distance\n",
        "levenshtein_distances = [Levenshtein.distance(generated, reference) for generated, reference in zip(generated_translations, references)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyf8p-Ppv8ct"
      },
      "source": [
        "# **Printing every evaluation metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q20W2nvCsVOT"
      },
      "outputs": [],
      "source": [
        "print(results_CER)\n",
        "print(results_WER)\n",
        "print(results_em)\n",
        "print(results_met)\n",
        "print(results_bleu)\n",
        "print(results_rouge)\n",
        "print(levenshtein_distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pteb9P9Nj_ny"
      },
      "outputs": [],
      "source": [
        "\"\"\"total_correct = 0\n",
        "total_samples = len(references)\n",
        "\n",
        "for generated, reference in zip(generated_translations, references):\n",
        "    levenshtein_distance = Levenshtein.distance(generated, reference)\n",
        "    max_length = max(len(generated), len(reference))\n",
        "    accuracy = 1 - (levenshtein_distance / max_length)\n",
        "    if accuracy >= 0.8:  # Adjust the threshold as needed\n",
        "        total_correct += 1\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A63_etjUHz1U"
      },
      "outputs": [],
      "source": [
        "\"\"\"import torch\n",
        "from transformers import MT5ForConditionalGeneration, AutoTokenizer\n",
        "#https://huggingface.co/docs/transformers/model_doc/mt5\n",
        "model_name = \"google/mt5-small\" # The variations it has -> mt5-small: 6, mt5-base: 12,mt5-large: 24, mt5-xl: 24, mt5-xxl: 24\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}